# recommender_systems_examples.ipynb (starter code)
# Jupyter Notebook for illustrating Recommender Systems concepts

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error

# -------------------------
# 1. Toy User–Item Rating Matrix
# -------------------------
# Rows = users, Columns = items (movies)
R = np.array([
    [5, 4, 0, 0, 1],
    [4, 0, 0, 2, 2],
    [0, 0, 5, 4, 0],
    [1, 2, 0, 0, 4],
])

print("Ratings matrix (users × items):\n", R)

plt.figure(figsize=(5,4))
sns.heatmap(R, annot=True, cmap="Blues", cbar=False)
plt.title("User–Item Ratings Matrix (sparse)")
plt.xlabel("Items")
plt.ylabel("Users")
plt.show()

# -------------------------
# 2. Content-Based Example (Linear Regression style)
# -------------------------
# Suppose items have features (e.g., [Action, Romance])
X_items = np.array([
    [1, 0],  # Item 1: Action
    [1, 1],  # Item 2: Action+Romance
    [0, 1],  # Item 3: Romance
    [0, 1],  # Item 4: Romance
    [1, 0],  # Item 5: Action
])

# User 1's known ratings for items 1, 2, 5
ratings_user1 = np.array([5, 4, 1])
features_user1 = np.array([X_items[0], X_items[1], X_items[4]])

# Solve least squares: theta ≈ preferences of user 1
theta_user1, _, _, _ = np.linalg.lstsq(features_user1, ratings_user1, rcond=None)
print("User 1 preference vector (content-based):", theta_user1)

# Predict rating for unseen item 3 (Romance)
pred_rating_item3 = theta_user1 @ X_items[2]
print("Predicted rating by User 1 for Item 3:", pred_rating_item3)

# -------------------------
# 3. Collaborative Filtering (Matrix Factorization)
# -------------------------
# Factorize R ≈ X * Theta^T using gradient descent

num_users, num_items = R.shape
num_features = 2  # latent features

# Initialize parameters
X = 0.1 * np.random.randn(num_items, num_features)  # item features
Theta = 0.1 * np.random.randn(num_users, num_features)  # user prefs

# Mask of observed ratings
mask = (R > 0).astype(float)

# Gradient descent
alpha = 0.01
lam = 0.1
num_iters = 5000

for it in range(num_iters):
    pred = X @ Theta.T
    error = (pred - R) * mask
    
    # Compute gradients
    X_grad = error @ Theta + lam * X
    Theta_grad = error.T @ X + lam * Theta
    
    # Update
    X -= alpha * X_grad
    Theta -= alpha * Theta_grad

# Predictions
R_pred = X @ Theta.T

print("\nPredicted Ratings Matrix (after factorization):\n", np.round(R_pred, 2))

plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
sns.heatmap(R, annot=True, cmap="Blues", cbar=False)
plt.title("Original Ratings (sparse)")
plt.xlabel("Items")
plt.ylabel("Users")

plt.subplot(1,2,2)
sns.heatmap(np.round(R_pred,1), annot=True, cmap="Greens", cbar=False)
plt.title("Predicted Ratings (completed)")
plt.xlabel("Items")
plt.ylabel("Users")
plt.show()

# -------------------------
# 4. Visualization of Learned Features
# -------------------------
plt.figure(figsize=(5,5))
plt.scatter(X[:,0], X[:,1], c='red', marker='x', label='Items')
plt.scatter(Theta[:,0], Theta[:,1], c='blue', marker='o', label='Users')
plt.xlabel("Latent Feature 1")
plt.ylabel("Latent Feature 2")
plt.legend()
plt.title("Learned User & Item Feature Space")
plt.show()




